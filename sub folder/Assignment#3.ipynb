{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVFTG0FjBykl"
      },
      "source": [
        "<p align=\"center\"><img width=\"50%\" src=\"https://aimodelsharecontent.s3.amazonaws.com/aimodshare_banner.jpg\" /></p>\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXxGTgJz152A"
      },
      "source": [
        "## Stanford Sentiment Treebank - Movie Review Classification Competition\n",
        "Let's share our models to a centralized leaderboard, so that we can collaborate and learn from the model experimentation process...\n",
        "\n",
        "**Instructions:**\n",
        "1.   Get data in and set up X_train / X_test / y_train\n",
        "2.   Preprocess data using keras Tokenizer/ Write and Save Preprocessor function\n",
        "3. Fit model on preprocessed data and save preprocessor function and model \n",
        "4. Generate predictions from X_test data and submit model to competition\n",
        "5. Repeat submission process to improve place on leaderboard\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Link to Repo"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### https://github.com/ruiqixue16/Stanford-SST-Sentiment-Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gSrVJwp3E9H"
      },
      "source": [
        "## 1. Get data in and set up X_train, X_test, y_train objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLTIaMB3ChSW",
        "outputId": "afb2237a-2ffd-4153-9dc2-b95718135bff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting aimodelshare==0.0.189\n",
            "  Downloading aimodelshare-0.0.189-py3-none-any.whl (967 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m967.8/967.8 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker==5.0.0\n",
            "  Downloading docker-5.0.0-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.0/147.0 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.7.0\n",
            "  Downloading onnxruntime-1.14.1-cp39-cp39-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pathlib>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (1.0.1)\n",
            "Collecting tf2onnx\n",
            "  Downloading tf2onnx-1.14.0-py3-none-any.whl (451 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.2/451.2 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-resources==5.10.0\n",
            "  Downloading importlib_resources-5.10.0-py3-none-any.whl (34 kB)\n",
            "Collecting boto3==1.26.69\n",
            "  Downloading boto3-1.26.69-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (2022.10.31)\n",
            "Collecting scikit-learn==1.2.1\n",
            "  Downloading scikit_learn-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (1.6.3)\n",
            "Collecting Pympler==0.9\n",
            "  Downloading Pympler-0.9.tar.gz (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.4/178.4 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting botocore==1.29.82\n",
            "  Downloading botocore-1.29.82-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: seaborn>=0.11.2 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (0.12.2)\n",
            "Collecting pydot==1.3.0\n",
            "  Downloading pydot-1.3.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (2.0.0+cu118)\n",
            "Collecting skl2onnx>=1.14.0\n",
            "  Downloading skl2onnx-1.14.0-py2.py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.0/294.0 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting shortuuid>=1.0.8\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Collecting tensorflow==2.9.2\n",
            "  Downloading tensorflow-2.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx==1.12.0\n",
            "  Downloading onnx-1.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyJWT>=2.4.0\n",
            "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
            "Collecting protobuf==3.19.6\n",
            "  Downloading protobuf-3.19.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxmltools>=1.6.1\n",
            "  Downloading onnxmltools-1.11.2-py2.py3-none-any.whl (322 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wget==3.2\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: psutil>=5.9.1 in /usr/local/lib/python3.9/dist-packages (from aimodelshare==0.0.189) (5.9.5)\n",
            "Collecting onnxconverter-common>=1.7.0\n",
            "  Downloading onnxconverter_common-1.13.0-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.8/83.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras2onnx>=1.7.0\n",
            "  Downloading keras2onnx-1.7.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.3/96.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.7.0\n",
            "  Downloading scipy-1.7.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.4/28.4 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse==1.6.3->aimodelshare==0.0.189) (0.40.0)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.9/dist-packages (from astunparse==1.6.3->aimodelshare==0.0.189) (1.16.0)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/dist-packages (from botocore==1.29.82->aimodelshare==0.0.189) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.9/dist-packages (from botocore==1.29.82->aimodelshare==0.0.189) (1.26.15)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.9/dist-packages (from docker==5.0.0->aimodelshare==0.0.189) (1.5.1)\n",
            "Requirement already satisfied: requests!=2.18.0,>=2.14.2 in /usr/local/lib/python3.9/dist-packages (from docker==5.0.0->aimodelshare==0.0.189) (2.27.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources==5.10.0->aimodelshare==0.0.189) (3.15.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/dist-packages (from onnx==1.12.0->aimodelshare==0.0.189) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.9/dist-packages (from onnx==1.12.0->aimodelshare==0.0.189) (4.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.9/dist-packages (from pydot==1.3.0->aimodelshare==0.0.189) (3.0.9)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.2.1->aimodelshare==0.0.189) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.2.1->aimodelshare==0.0.189) (1.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (23.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (2.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (3.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (67.6.1)\n",
            "Collecting keras-preprocessing>=1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (0.2.0)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (1.53.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (0.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (1.4.0)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (16.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (0.32.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare==0.0.189) (3.3.0)\n",
            "Collecting fire\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from onnxruntime>=1.7.0->aimodelshare==0.0.189) (1.11.1)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.9/dist-packages (from seaborn>=0.11.2->aimodelshare==0.0.189) (3.7.1)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.9/dist-packages (from seaborn>=0.11.2->aimodelshare==0.0.189) (1.5.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->aimodelshare==0.0.189) (3.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->aimodelshare==0.0.189) (3.11.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->aimodelshare==0.0.189) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->aimodelshare==0.0.189) (3.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->aimodelshare==0.0.189) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->aimodelshare==0.0.189) (3.25.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->aimodelshare==0.0.189) (8.4.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->aimodelshare==0.0.189) (4.39.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->aimodelshare==0.0.189) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->aimodelshare==0.0.189) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.2->aimodelshare==0.0.189) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.25->seaborn>=0.11.2->aimodelshare==0.0.189) (2022.7.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->aimodelshare==0.0.189) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->aimodelshare==0.0.189) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->aimodelshare==0.0.189) (3.4)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (1.8.1)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (2.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (3.4.3)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.8.1->aimodelshare==0.0.189) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->onnxruntime>=1.7.0->aimodelshare==0.0.189) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (6.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare==0.0.189) (3.2.2)\n",
            "Building wheels for collected packages: Pympler, wget, fire\n",
            "  Building wheel for Pympler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Pympler: filename=Pympler-0.9-py3-none-any.whl size=164822 sha256=b7f659f34ea866c6758fdf79edec142832474c45e5fcca9b25ad0d6c0108e08f\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/84/9a/0e7aa69b52bc9dc13ea25679c8d8f1dc11bc5b5289db23d9f3\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9676 sha256=b976d8a2dc7b58f12ceaf193f13dc9a36d27072bb95384226ad980a25a7f23a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/5f/3e/46cc37c5d698415694d83f607f833f83f0149e49b3af9d0f38\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116952 sha256=cec546dd07040ea559885f2d3e0b35bc7613f183c6f8eaed0e442e1f9d639c03\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/f1/89/b9ea2bf8f80ec027a88fef1d354b3816b4d3d29530988972f6\n",
            "Successfully built Pympler wget fire\n",
            "Installing collected packages: wget, Pympler, keras, flatbuffers, tensorflow-estimator, tensorboard-data-server, shortuuid, scipy, PyJWT, pydot, protobuf, keras-preprocessing, jmespath, importlib-resources, humanfriendly, fire, scikit-learn, onnx, docker, coloredlogs, botocore, tf2onnx, s3transfer, onnxruntime, onnxconverter-common, google-auth-oauthlib, tensorboard, skl2onnx, keras2onnx, boto3, tensorflow, onnxmltools, aimodelshare\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.3.3\n",
            "    Uninstalling flatbuffers-23.3.3:\n",
            "      Successfully uninstalled flatbuffers-23.3.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.0\n",
            "    Uninstalling tensorboard-data-server-0.7.0:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "  Attempting uninstall: pydot\n",
            "    Found existing installation: pydot 1.4.2\n",
            "    Uninstalling pydot-1.4.2:\n",
            "      Successfully uninstalled pydot-1.4.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib-resources 5.12.0\n",
            "    Uninstalling importlib-resources-5.12.0:\n",
            "      Successfully uninstalled importlib-resources-5.12.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.2\n",
            "    Uninstalling tensorboard-2.12.2:\n",
            "      Successfully uninstalled tensorboard-2.12.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "arviz 0.15.1 requires scipy>=1.8.0, but you have scipy 1.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyJWT-2.6.0 Pympler-0.9 aimodelshare-0.0.189 boto3-1.26.69 botocore-1.29.82 coloredlogs-15.0.1 docker-5.0.0 fire-0.5.0 flatbuffers-1.12 google-auth-oauthlib-0.4.6 humanfriendly-10.0 importlib-resources-5.10.0 jmespath-1.0.1 keras-2.9.0 keras-preprocessing-1.1.2 keras2onnx-1.7.0 onnx-1.12.0 onnxconverter-common-1.13.0 onnxmltools-1.11.2 onnxruntime-1.14.1 protobuf-3.19.6 pydot-1.3.0 s3transfer-0.6.0 scikit-learn-1.2.1 scipy-1.7.0 shortuuid-1.0.11 skl2onnx-1.14.0 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorflow-2.9.2 tensorflow-estimator-2.9.0 tf2onnx-1.14.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "#install aimodelshare library\n",
        "! pip install aimodelshare==0.0.189"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3PiJXBhC5y-",
        "outputId": "a3db291a-a48a-4ea9-f2d4-ad4fea46d527"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading [=============================================>   ]\n",
            "\n",
            "Data downloaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# Get competition data\n",
        "from aimodelshare import download_data\n",
        "download_data('public.ecr.aws/y2e2a1d6/sst2_competition_data-repository:latest') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT0qFCZFNzHq",
        "outputId": "4a65e0c3-b367-4e71-e92c-c42161d12b32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    The Rock is destined to be the 21st Century 's...\n",
              "1    The gorgeously elaborate continuation of `` Th...\n",
              "2    Singer/composer Bryan Adams contributes a slew...\n",
              "3                 Yet the act is still charming here .\n",
              "4    Whether or not you 're enlightened by any of D...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set up X_train, X_test, and y_train_labels objects\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "X_train=pd.read_csv(\"sst2_competition_data/X_train.csv\", squeeze=True)\n",
        "X_test=pd.read_csv(\"sst2_competition_data/X_test.csv\", squeeze=True)\n",
        "\n",
        "y_train_labels=pd.read_csv(\"sst2_competition_data/y_train_labels.csv\", squeeze=True)\n",
        "\n",
        "# ohe encode Y data\n",
        "y_train = pd.get_dummies(y_train_labels)\n",
        "\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEzPoXPj3V7u"
      },
      "source": [
        "##2.   Preprocess data using keras tokenizer / Write and Save Preprocessor function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16QV9Y9TC3B3",
        "outputId": "71511163-e053-4bc7-c852-10922687cf9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6920, 40)\n",
            "(1821, 40)\n"
          ]
        }
      ],
      "source": [
        "# This preprocessor function makes use of the tf.keras tokenizer\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Build vocabulary from training text data\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# preprocessor tokenizes words and makes sure all documents have the same length\n",
        "def preprocessor(data, maxlen=40, max_words=10000):\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(data)\n",
        "\n",
        "    word_index = tokenizer.word_index\n",
        "    X = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "    return X\n",
        "\n",
        "print(preprocessor(X_train).shape)\n",
        "print(preprocessor(X_test).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0myUKXlkF6c"
      },
      "source": [
        "## Discuss the dataset in general terms and describe why building a predictive model using this data might be practically useful.  Who could benefit from a model like this? Explain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gViz9hOwkHCi",
        "outputId": "12e5a0db-99a4-470e-8b0b-9730544d6ab3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    The Rock is destined to be the 21st Century 's...\n",
              "1    The gorgeously elaborate continuation of `` Th...\n",
              "2    Singer/composer Bryan Adams contributes a slew...\n",
              "3                 Yet the act is still charming here .\n",
              "4    Whether or not you 're enlightened by any of D...\n",
              "5    Just the labour involved in creating the layer...\n",
              "6    Part of the charm of Satin Rouge is that it av...\n",
              "7    a screenplay more ingeniously constructed than...\n",
              "8             `` Extreme Ops '' exceeds expectations .\n",
              "9    Good fun , good action , good acting , good di...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "c-LmwOmhmD4U",
        "outputId": "acce0cc0-a618-40ee-9dee-f47a32a455b9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-90573e18-afd9-4781-937c-6d41ec20e322\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Negative</th>\n",
              "      <th>Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90573e18-afd9-4781-937c-6d41ec20e322')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90573e18-afd9-4781-937c-6d41ec20e322 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90573e18-afd9-4781-937c-6d41ec20e322');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Negative  Positive\n",
              "0         0         1\n",
              "1         0         1\n",
              "2         0         1\n",
              "3         0         1\n",
              "4         0         1\n",
              "5         0         1\n",
              "6         0         1\n",
              "7         0         1\n",
              "8         0         1\n",
              "9         0         1"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh7xZyjmmGSc"
      },
      "source": [
        "### The Stanford Sentiment Treebank v2 (SST2) is a collection of fully classified parse trees that enables a thorough examination of the compositional effects of sentiment in language. It contains 215,154 distinct sentennces, each with a sentiment attached. Building a predictive model using this dataset can be useful for all types of projects and industries involving sentiment analysis.\n",
        "\n",
        "### For example, we can predict the sentiments of future movies with given set of comments. This can help production companies better navigate their production strategies and marketing strategies based on those sentiment predictions. The impact of this model may extend beyond the film industry. This can be applied to resturants, TV shows, or anywhere involving reviews.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwNKs0wP4r5s"
      },
      "source": [
        "## Run at least three: Use an Embedding layer and LSTM layers in at least one model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgSs5PAtPCZH",
        "outputId": "882cd9e3-ac8c-40ff-b456-dff67990d3f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "173/173 [==============================] - 28s 91ms/step - loss: 0.6611 - acc: 0.6178 - val_loss: 0.7173 - val_acc: 0.4639\n"
          ]
        }
      ],
      "source": [
        "# Train and submit model 2 using same preprocessor (note that you could save a new preprocessor, but we will use the same one for this example).\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(Embedding(10000, 16, input_length=40))\n",
        "model1.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
        "model1.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
        "model1.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
        "model1.add(LSTM(32, dropout=0.2))\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model1.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model1.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=1,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5em_0xXTixI",
        "outputId": "b8148f67-b7f5-49fe-c922-830138a3000f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your preprocessor is now saved to 'preprocessor.zip'\n"
          ]
        }
      ],
      "source": [
        "import aimodelshare as ai\n",
        "ai.export_preprocessor(preprocessor,\"\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIdmSpYVPYAw"
      },
      "outputs": [],
      "source": [
        "# Save keras model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_model = model_to_onnx(model1, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model1.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO7npwg6T23V",
        "outputId": "ba484810-cd28-4285-824f-44f25dd7d5a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI Modelshare Username:··········\n",
            "AI Modelshare Password:··········\n",
            "AI Model Share login credentials set successfully.\n"
          ]
        }
      ],
      "source": [
        "#Set credentials using modelshare.org username/password\n",
        "\n",
        "from aimodelshare.aws import set_credentials\n",
        "    \n",
        "apiurl=\"https://rlxjxnoql9.execute-api.us-east-1.amazonaws.com/prod/m\" #This is the unique rest api that powers this specific Playground\n",
        "\n",
        "set_credentials(apiurl=apiurl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESZXa3ueTrcq"
      },
      "outputs": [],
      "source": [
        "#Instantiate Competition\n",
        "\n",
        "mycompetition= ai.Competition(apiurl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nszPPrfwPlUk",
        "outputId": "fc5f967a-aaa0-4729-9ba8-3e9d8a7a0690"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 [==============================] - 1s 20ms/step\n",
            "Insert search tags to help users find your model (optional): model1\n",
            "Provide any useful notes about your model (optional): LSTM\n",
            "\n",
            "Your model has been submitted as model version 313\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:2763\n"
          ]
        }
      ],
      "source": [
        "#Submit Model 1: \n",
        "\n",
        "#-- Generate predicted y values (Model 1)\n",
        "prediction_column_index=model1.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 2 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model1.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTX8rsIIUYC4"
      },
      "source": [
        "## Run at least three: Use an Embedding layer and Conv1d layers in at least one model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOEd5cVkUc7p",
        "outputId": "06b904d8-64f1-4da3-f218-fa46af850e34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "173/173 [==============================] - 3s 11ms/step - loss: 1.0238 - acc: 0.5000 - val_loss: 0.6946 - val_acc: 0.5000\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM,Embedding\n",
        "\n",
        "maxlen = 40\n",
        "model2 = Sequential()\n",
        "model2.add(layers.Embedding(10000, 8, input_length=maxlen))\n",
        "model2.add(layers.Conv1D(32, 7, activation='relu')) \n",
        "model2.add(layers.MaxPooling1D(2)) \n",
        "model2.add(layers.Conv1D(32, 7, activation='relu'))\n",
        "model2.add(layers.GlobalMaxPooling1D())\n",
        "model2.add(layers.Dense(1))\n",
        "\n",
        "model2.compile(optimizer=RMSprop(lr=1e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model2.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=1,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8KcnpPiXJPZ"
      },
      "outputs": [],
      "source": [
        "# Save keras model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_model = model_to_onnx(model2, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model2.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvlUsFZGXOBe",
        "outputId": "22d30243-5e00-4544-be95-561f74ea0a40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 [==============================] - 0s 2ms/step\n",
            "Insert search tags to help users find your model (optional): model2\n",
            "Provide any useful notes about your model (optional): conv1d\n",
            "\n",
            "Your model has been submitted as model version 319\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:2763\n"
          ]
        }
      ],
      "source": [
        "#Submit Model 2: \n",
        "\n",
        "#-- Generate predicted y values (Model 2)\n",
        "prediction_column_index=model2.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 2 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model2.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeq6mTTLXs1Y"
      },
      "source": [
        "## Run at least three: Use transfer learning with glove embeddings for at least one of these models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxRj1tA2X5jq",
        "outputId": "27ae0838-4ff8-4f8d-fb5d-9486d2c94eea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-04-17 22:42:39--  http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/wordvecs/glove.6B.zip [following]\n",
            "--2023-04-17 22:42:39--  https://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip [following]\n",
            "--2023-04-17 22:42:39--  https://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182753 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.05MB/s    in 2m 40s  \n",
            "\n",
            "2023-04-17 22:45:19 (5.15 MB/s) - ‘glove.6B.zip’ saved [862182753/862182753]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# What if we wanted to use a matrix of pretrained embeddings?  Same as transfer learning before, but now we are importing a pretrained Embedding matrix:\n",
        "# Download Glove embedding matrix weights (Might take 10 mins or so!)\n",
        "! wget http://nlp.stanford.edu/data/wordvecs/glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCZVnCGeYlzq",
        "outputId": "e638ed4d-4148-4d02-e433-7d69ec94c354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "  inflating: glove.6B.50d.txt        \n"
          ]
        }
      ],
      "source": [
        "! unzip glove.6B.zip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxcRAMurafmN"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCT8S_yxYyRV",
        "outputId": "10d5f447-4c56-47e0-e471-f01bc3815524"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 400001 word vectors.\n"
          ]
        }
      ],
      "source": [
        "# Extract embedding data for 100 feature embedding matrix\n",
        "glove_dir = os.getcwd()\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ioy6mCpEcHy8"
      },
      "outputs": [],
      "source": [
        "# Build embedding matrix\n",
        "embedding_dim = 100 # change if you use txt files using larger number of features\n",
        "word_index = tokenizer.word_index\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if i < max_words:\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtvLFyI1cl3K",
        "outputId": "6ee6087a-0b59-4364-b7af-5a8ab3807513"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_21 (Embedding)    (None, 40, 100)           1000000   \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 4000)              0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 32)                128032    \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,128,098\n",
            "Trainable params: 1,128,098\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Set up same model architecture as before and then import Glove weights to Embedding layer:\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(32, activation='relu'))\n",
        "model3.add(Dense(2, activation='softmax'))\n",
        "model3.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAtXwQLddA8P",
        "outputId": "3af46eb2-7fa0-491e-a687-8a611a91a9b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "173/173 [==============================] - 2s 9ms/step - loss: 0.6859 - acc: 0.6131 - val_loss: 0.7404 - val_acc: 0.1488\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Add weights in same manner as transfer learning and turn of trainable option before fitting model to freeze weights.\n",
        "model3.layers[0].set_weights([embedding_matrix])\n",
        "model3.layers[0].trainable = False\n",
        "\n",
        "\n",
        "\n",
        "model3.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model3.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=1,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)\n",
        "model3.save_weights('pre_trained_glove_model.h5')\n",
        "\n",
        "# this is the end\n",
        "# Training data small to speed up training. Increase for better fit.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvPEm0cpgiro"
      },
      "outputs": [],
      "source": [
        "# Save keras model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_model = model_to_onnx(model3, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model3.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUQLZUVVgpJa",
        "outputId": "f58741cd-f1f2-432a-97b3-4f115b24c12a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 [==============================] - 0s 3ms/step\n",
            "Insert search tags to help users find your model (optional): 摸的l\n",
            "Provide any useful notes about your model (optional): Transfer learning\n",
            "\n",
            "Your model has been submitted as model version 324\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:2763\n"
          ]
        }
      ],
      "source": [
        "#Submit Model 3: \n",
        "\n",
        "#-- Generate predicted y values (Model 3)\n",
        "prediction_column_index=model3.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 3 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model3.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOGXwppct0KI"
      },
      "outputs": [],
      "source": [
        "! pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7o_zA3fv-ra"
      },
      "outputs": [],
      "source": [
        "#Separate validation data \n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train_split, x_val, y_train_split, y_val = train_test_split(\n",
        "     X_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olzZ7aposfwH",
        "outputId": "27839e1b-0e68-4bdc-c728-2aefb6941c30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 3 Complete [00h 00m 08s]\n",
            "val_accuracy: 0.6748554706573486\n",
            "\n",
            "Best val_accuracy So Far: 0.6849710941314697\n",
            "Total elapsed time: 00h 01m 45s\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "import keras_tuner as kt\n",
        "\n",
        "#Define model structure & parameter search space with function\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(Embedding(10000, 16, input_length=40))\n",
        "    model.add(LSTM(units=hp.Int(\"units\", min_value=32, max_value=512, step=32), #range 32-512 inclusive, minimum step between tested values is 32\n",
        "                   return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    model.compile(\n",
        "        optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "#initialize the tuner (which will search through parameters)\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model, \n",
        "    objective=\"val_accuracy\", # objective to optimize\n",
        "    max_trials=3, #max number of trials to run during search\n",
        "    executions_per_trial=1, #higher number reduces variance of results; guages model performance more accurately \n",
        "    overwrite=True,\n",
        "    directory=\"tuning_model\",\n",
        "    project_name=\"tuning_units\",\n",
        ")\n",
        "\n",
        "tuner.search(preprocessor(x_train_split), y_train_split, epochs=1, validation_data=(preprocessor(x_val), y_val))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YaEbvJ2yND1",
        "outputId": "c26eb034-bac9-4082-960b-66dcb52ecffa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "217/217 [==============================] - 67s 298ms/step - loss: 0.6752 - accuracy: 0.5908\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa29638e040>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Build model with best hyperparameters\n",
        "\n",
        "# Get the top 2 hyperparameters.\n",
        "best_hps = tuner.get_best_hyperparameters(5)\n",
        "# Build the model with the best hp.\n",
        "tuned_model = build_model(best_hps[0])\n",
        "# Fit with the entire dataset.\n",
        "tuned_model.fit(x=preprocessor(X_train), y=y_train, epochs=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvLuIvOjHLH2"
      },
      "outputs": [],
      "source": [
        "# Save keras model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_model = model_to_onnx(tuned_model, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"tuned_model.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMidHABfHVN7",
        "outputId": "620e86e5-dca0-410d-ddab-3e1abea59cb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 [==============================] - 3s 46ms/step\n",
            "Insert search tags to help users find your model (optional): \n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 3\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:2763\n"
          ]
        }
      ],
      "source": [
        "#Submit Model 3: \n",
        "\n",
        "#-- Generate predicted y values (Model 3)\n",
        "prediction_column_index=tuned_model.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 1 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"tuned_model.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFzs90ZLqwos"
      },
      "source": [
        "## Discuss which models performed better and point out relevant hyper-parameter values for successful models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhsdcFm2rGxD"
      },
      "source": [
        "#### among the three models I submitted, the LSTM model performed the best with an accuracy score of 0.66. The model has four LSTM layers all with feature depth of 32. The embedding layer has 10000 as input dim, 16 as output, and 40 as input length. \n",
        "\n",
        "#### However, this is still not ideal. I will try to tune more after sharing my notes with my teammates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLIOavv1sNqj"
      },
      "source": [
        "## Fit and submit up to three more models after learning from your team"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjffcLTNsktn"
      },
      "source": [
        "#### after our team discussion, we have all suggested that LSTM models performed the best. One of my teammates suggested that he had a better result with more epochs, so I will try now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwfvzD66t7Og"
      },
      "source": [
        "### submit first model after discussion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNNCirj8sSR_",
        "outputId": "61543508-bf12-4af0-afdb-91ddf380c058"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "173/173 [==============================] - 27s 106ms/step - loss: 0.6485 - acc: 0.6313 - val_loss: 0.7718 - val_acc: 0.5007\n",
            "Epoch 2/5\n",
            "173/173 [==============================] - 15s 88ms/step - loss: 0.4756 - acc: 0.7706 - val_loss: 0.6439 - val_acc: 0.6503\n",
            "Epoch 3/5\n",
            "173/173 [==============================] - 14s 81ms/step - loss: 0.3498 - acc: 0.8531 - val_loss: 0.5539 - val_acc: 0.7290\n",
            "Epoch 4/5\n",
            "173/173 [==============================] - 14s 78ms/step - loss: 0.2802 - acc: 0.8862 - val_loss: 0.6677 - val_acc: 0.6879\n",
            "Epoch 5/5\n",
            "173/173 [==============================] - 16s 95ms/step - loss: 0.2317 - acc: 0.9059 - val_loss: 0.6500 - val_acc: 0.7247\n"
          ]
        }
      ],
      "source": [
        "# Train and submit model 2 using same preprocessor (note that you could save a new preprocessor, but we will use the same one for this example).\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "\n",
        "model4 = Sequential()\n",
        "model4.add(Embedding(10000, 50, input_length=40))\n",
        "model4.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
        "model4.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
        "model4.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
        "model4.add(LSTM(32, dropout=0.2))\n",
        "model4.add(Flatten())\n",
        "model4.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model4.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model4.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=5,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKNqcfadtD-W",
        "outputId": "36eca08b-c0f9-4bab-8bd9-c078ba3a47a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your preprocessor is now saved to 'preprocessor.zip'\n"
          ]
        }
      ],
      "source": [
        "import aimodelshare as ai\n",
        "ai.export_preprocessor(preprocessor,\"\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8EE994whtIST"
      },
      "outputs": [],
      "source": [
        "# Save keras model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_model = model_to_onnx(model4, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model4.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PneOS7wZtK_z"
      },
      "outputs": [],
      "source": [
        "#Instantiate Competition\n",
        "\n",
        "mycompetition= ai.Competition(apiurl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJwou5KJtQVt",
        "outputId": "bf2f9c33-b916-470b-c377-9d965934c1bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 [==============================] - 6s 31ms/step\n",
            "Insert search tags to help users find your model (optional): model 4\n",
            "Provide any useful notes about your model (optional): epoch 5\n",
            "\n",
            "Your model has been submitted as model version 472\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:2763\n"
          ]
        }
      ],
      "source": [
        "#Submit Model 4: \n",
        "\n",
        "#-- Generate predicted y values (Model 1=4)\n",
        "prediction_column_index=model4.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 4 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model4.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn3-aLj6t-0P"
      },
      "source": [
        "### submit second model after discussion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILBIRm3RuAqO",
        "outputId": "a272750e-5122-4e9e-f876-285ca3ff59f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "173/173 [==============================] - 14s 57ms/step - loss: 0.6346 - acc: 0.6364 - val_loss: 0.7145 - val_acc: 0.6546\n",
            "Epoch 2/5\n",
            "173/173 [==============================] - 6s 36ms/step - loss: 0.4480 - acc: 0.7971 - val_loss: 0.6650 - val_acc: 0.7153\n",
            "Epoch 3/5\n",
            "173/173 [==============================] - 10s 56ms/step - loss: 0.3277 - acc: 0.8661 - val_loss: 0.6297 - val_acc: 0.7160\n",
            "Epoch 4/5\n",
            "173/173 [==============================] - 7s 39ms/step - loss: 0.2596 - acc: 0.8969 - val_loss: 0.5028 - val_acc: 0.7666\n",
            "Epoch 5/5\n",
            "173/173 [==============================] - 9s 49ms/step - loss: 0.2164 - acc: 0.9146 - val_loss: 0.4959 - val_acc: 0.7818\n"
          ]
        }
      ],
      "source": [
        "model5 = Sequential()\n",
        "model5.add(Embedding(10000, 50, input_length=40))\n",
        "model5.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
        "model5.add(LSTM(32, dropout=0.2))\n",
        "model5.add(Flatten())\n",
        "model5.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model5.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model5.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=5,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "nnqXZdzTujl0"
      },
      "outputs": [],
      "source": [
        "# Save keras model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_model = model_to_onnx(model5, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model5.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U87zrigpuos-",
        "outputId": "0b2e7656-99f0-48b3-f6cb-a27d68ee55fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 [==============================] - 3s 21ms/step\n",
            "Insert search tags to help users find your model (optional): model 5\n",
            "Provide any useful notes about your model (optional): simple LSTM\n",
            "\n",
            "Your model has been submitted as model version 473\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:2763\n"
          ]
        }
      ],
      "source": [
        "#Submit Model 5: \n",
        "\n",
        "#-- Generate predicted y values (Model 1=4)\n",
        "prediction_column_index=model5.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 5 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model5.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jndsez67vBvY"
      },
      "source": [
        "### submit third model after discussion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At2gIpYBvBZw",
        "outputId": "bb800935-39fb-4ba3-e16d-7726f379a4b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "173/173 [==============================] - 30s 114ms/step - loss: 0.6587 - acc: 0.6216 - val_loss: 0.8036 - val_acc: 0.5173\n",
            "Epoch 2/5\n",
            "173/173 [==============================] - 17s 97ms/step - loss: 0.5055 - acc: 0.7536 - val_loss: 0.7360 - val_acc: 0.5838\n",
            "Epoch 3/5\n",
            "173/173 [==============================] - 17s 99ms/step - loss: 0.3760 - acc: 0.8351 - val_loss: 0.5815 - val_acc: 0.7254\n",
            "Epoch 4/5\n",
            "173/173 [==============================] - 16s 95ms/step - loss: 0.2961 - acc: 0.8777 - val_loss: 0.4683 - val_acc: 0.8006\n",
            "Epoch 5/5\n",
            "173/173 [==============================] - 16s 92ms/step - loss: 0.2460 - acc: 0.9025 - val_loss: 0.6875 - val_acc: 0.7225\n"
          ]
        }
      ],
      "source": [
        "model6 = Sequential()\n",
        "model6.add(Embedding(10000, 50, input_length=40))\n",
        "model6.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
        "model6.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
        "model6.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
        "model6.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
        "model6.add(LSTM(32, dropout=0.2))\n",
        "model6.add(Flatten())\n",
        "model6.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model6.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model6.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=5,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "lVy_tC3Sv4ft"
      },
      "outputs": [],
      "source": [
        "# Save keras model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_model = model_to_onnx(model6, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model6.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfbhzmAExj0Q",
        "outputId": "d9d621d0-f2d6-46d3-a02a-5013d6557b7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 [==============================] - 5s 33ms/step\n",
            "Insert search tags to help users find your model (optional): model 6\n",
            "Provide any useful notes about your model (optional): more LSTM layers\n",
            "\n",
            "Your model has been submitted as model version 474\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:2763\n"
          ]
        }
      ],
      "source": [
        "#Submit Model 6: \n",
        "\n",
        "#-- Generate predicted y values (Model 1=4)\n",
        "prediction_column_index=model6.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 6 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model6.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRTnXv1tyHkO"
      },
      "source": [
        "### submit fourth model after discussion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr52g_DbyKuL",
        "outputId": "d4dc49ad-78dc-49ec-b0d9-f864205981f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "173/173 [==============================] - 49s 190ms/step - loss: 0.6688 - acc: 0.6125 - val_loss: 0.8962 - val_acc: 0.1488\n",
            "Epoch 2/5\n",
            "173/173 [==============================] - 22s 125ms/step - loss: 0.6094 - acc: 0.6653 - val_loss: 0.8085 - val_acc: 0.5065\n",
            "Epoch 3/5\n",
            "173/173 [==============================] - 22s 127ms/step - loss: 0.4573 - acc: 0.7868 - val_loss: 0.7207 - val_acc: 0.6091\n",
            "Epoch 4/5\n",
            "173/173 [==============================] - 23s 134ms/step - loss: 0.3560 - acc: 0.8445 - val_loss: 0.9301 - val_acc: 0.5405\n",
            "Epoch 5/5\n",
            "173/173 [==============================] - 23s 133ms/step - loss: 0.2923 - acc: 0.8799 - val_loss: 0.5087 - val_acc: 0.7587\n"
          ]
        }
      ],
      "source": [
        "model7 = Sequential()\n",
        "model7.add(Embedding(10000, 50, input_length=40))\n",
        "model7.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
        "model7.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
        "model7.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
        "model7.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
        "model7.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
        "model7.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
        "model7.add(LSTM(32, dropout=0.2))\n",
        "model7.add(Flatten())\n",
        "model7.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model7.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model7.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=5,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "-vl8Py9oyXtr"
      },
      "outputs": [],
      "source": [
        "# Save keras model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_model = model_to_onnx(model7, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model7.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvXSceO6ycC-",
        "outputId": "18cf9555-9160-4716-fe73-133e9727e64b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 [==============================] - 9s 49ms/step\n",
            "Insert search tags to help users find your model (optional): model 7\n",
            "Provide any useful notes about your model (optional): more LSTM\n",
            "\n",
            "Your model has been submitted as model version 475\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:2763\n"
          ]
        }
      ],
      "source": [
        "#Submit Model 7: \n",
        "\n",
        "#-- Generate predicted y values (Model 1=4)\n",
        "prediction_column_index=model7.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 7 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model7.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDAqB0Nczm4Y"
      },
      "source": [
        "## Discuss results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeS4XKJpzotO"
      },
      "source": [
        "#### Out of all the three LSTM models I've tried, the second model (model 6) has the accuracy score of 0.8. It has four LSTM layers and the embedding layer has 10000 input, 50 output, and an input length of 40. I've tried adding more or deleting layers, but neither has shown imrpovement. However, all were better than my previous ones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQORu45_0PvI"
      },
      "source": [
        "## Discuss which models you tried and which models performed better and point out relevant hyper-parameter values for successful models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKgQhBvx0RDk"
      },
      "source": [
        "#### In this assignment, I have tried models with LSTM, Conv1d, and transfer learning model using glove. LSTM layers performed the best in general, and transfer learning model was the worst. My best LSTM model has an accuracy score of 0.8 with four LSTM layers, each with 32 features. The embedding layer has 10000 output, 50 output, and an input length of 40. The epochs was 5."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
