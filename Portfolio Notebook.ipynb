{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to repo:\n",
    "https://github.com/ruiqixue16/adv_ml_final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project #1: Report on U.N. World Happiness Data\n",
    "\n",
    "### Link:\n",
    "https://github.com/ruiqixue16/World-Happiness-ML-Models\n",
    "\n",
    "### Description:\n",
    "The World Happiness Report is a publication of the United Nations, which takes into account a variety of factors such as GDP per capita, social support, and generosity, and ranks countries by their happiness levels. The preprocessed x train dataset has 88 rows of observations with 26 features.\n",
    "\n",
    "### Types of Models\n",
    "In this project, we used the data from the report to build predictive models and see what features are important at predicting happiness levels. The models used in this report include RandomForest, GradientBoosting, Bagging and SVC with GridSearchCV applied.\n",
    "\n",
    "### Models and Comparisons:\n",
    "My BaggingClassifier model with parameters n_estimators = 50, n_jobs = 3 has the highest f1 and accuracy among all the models I tried, and my random forest models consistently score better than my neural network and gradient boosting models. This finding concurs with the leaderboard. The top three models on the leaderboard all use Gradient Boosting. \n",
    "\n",
    "\n",
    "# Project #2: Report on Covid Positive X-Ray image data\n",
    "\n",
    "\n",
    "### Link:\n",
    "https://github.com/ruiqixue16/Covid_Xrays_Image_ML_Models\n",
    "\n",
    "### Description:\n",
    "The dataset is provided by Chowdhury et al. in the paper “Can AI help in screening Viral and COVID-19 pneumonia?”. It contains three categories of chest x-ray images, including covid, normal, and viral pneumonia. In preprocessing, we limit the count of images in each category to 1345 to downsize the dataset and avoid imbalance of data. \n",
    "\n",
    "### Types of Models\n",
    "In this project, we used the data from the report to build predictive models that can detect Covid and pneumonia from normal chest x-rays. It can automate the process of covid-19 detection. The models used in this project include CNN sequential models with Conv2D and MaxPooling layers, and transfer learning using ResNets50 and inception models. \n",
    "\n",
    "### Models and Comparisons:\n",
    "Out of all the models I tried, a six-layer CNN model with 5 epoch yielded the best result, with an over 0.9 f1 score. Specifically, my model has two Conv2D layers with 32 filters, two Conv2D layers with 64 filters, one with 128, and one with 512 filters.I chose this particular combination of settings based on my comparison of multiple trial results. Through my analysis, I discovered that using a moderate number of layers and smaller filter sizes resulted in more accurate predictions for the dataset. In contrast, larger filter sizes can lead to overfitting, and using fewer layers often leads to weaker predictive abilities. Consequently, I concluded that this combination offers a strong predictive power.\n",
    "\n",
    "The transfer learning model using inception was quite powerful as well, and much easier to implement.\n",
    "\n",
    "\n",
    "# Project #3: Text Classification Using the Stanford SST Sentiment Dataset\n",
    "\n",
    "### Link: \n",
    "https://github.com/ruiqixue16/Stanford-SST-Sentiment-Dataset\n",
    "\n",
    "### Description:\n",
    "The Stanford Sentiment Treebank v2 (SST2) is a collection of fully classified parse trees that enables a thorough examination of the compositional effects of sentiment in language. It contains 215,154 distinct sentences, each with a sentiment attached. \n",
    "\n",
    "### Types of Models\n",
    "Building a predictive model using this dataset can be useful for all types of projects and industries involving sentiment analysis. For example, we can predict the sentiments of future movies with a given set of comments, and the impact expands beyond the entertainment industry. In this project, I have used embedding layers with LSTM, Conv1D, and transfer learning with glove embeddings to build predictive models.\n",
    "\n",
    "\n",
    "### Models and Comparisons:\n",
    "Out of all the models I tried, my LSTM model performed the best. The model used four LSTM layers, each with 32 features and an embedding layer with 10000 input, 50 output, and an input length of 40. Compared to the leaderboard, my model doesn’t have as many dense layers as the top models. The top models have at least two dense layers, while my best model only had one.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
